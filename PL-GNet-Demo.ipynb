{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T02:26:58.711273Z",
     "start_time": "2019-07-27T02:26:54.918034Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "#from tensorflow.python.ops import rnn, rnn_cell\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import tensorflow.contrib.slim as slim\n",
    "from compute_mcc import *\n",
    "#import scipy.io as sio\n",
    "import math\n",
    "import h5py\n",
    "#from compute_mcc import compute_mcc,metrics,_fast_hist,label_accuracy_score\n",
    "from hilbert import hilbertCurve\n",
    "#from compute_IoU import compute_precision,bb_IoU\n",
    "# sys.path.append('.')\n",
    "import os,sys\n",
    "from scipy import signal\n",
    "import time\n",
    "import skimage\n",
    "import skimage.io, skimage.transform\n",
    "from skimage.transform import resize\n",
    "from skimage.util import view_as_windows\n",
    "import scipy.misc\n",
    "import scipy.io as sio\n",
    "from skimage import img_as_uint\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas\n",
    "import glob \n",
    "import datetime\n",
    "from skimage.color import rgb2ycbcr \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pywt\n",
    "# import cv2\n",
    "import re\n",
    "from PIL import Image\n",
    "import os\n",
    "import bisect\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fileters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T02:27:05.839826Z",
     "start_time": "2019-07-27T02:27:05.826926Z"
    }
   },
   "outputs": [],
   "source": [
    "SRM_Kernel = np.array([\n",
    "    [[0,0,0,0,0],[0,0,0,0,0],[0,0,-1,1,0],[0,0,0,0,0],[0,0,0,0,0]],\n",
    "    [[0,0,0,0,0],[0,0,0,0,0],[0,1,-1,0,0],[0,0,0,0,0],[0,0,0,0,0]],\n",
    "    [[0,0,0,0,0],[0,0,1,0,0],[0,0,-1,0,0],[0,0,0,0,0],[0,0,0,0,0]],\n",
    "    [[0,0,0,0,0],[0,0,0,0,0],[0,0,-1,0,0],[0,0,1,0,0],[0,0,0,0,0]],\n",
    "    [[0,0,0,0,0],[0,0,0,0,0],[0,1,-2,1,0],[0,0,0,0,0],[0,0,0,0,0]],\n",
    "    [[0,0,0,0,0],[0,-1,2,-1,0],[0,2,-4,2,0],[0,-1,2,-1,0],[0,0,0,0,0]],\n",
    "    [[-1,2,-2,2,-1],[2,-6,8,-6,2],[-2,8,-12,8,-2],[2,-6,8,-6,2],[-1,2,-2,2,-1]],\n",
    "])\n",
    "SRM_Kernel = np.vstack((SRM_Kernel, SRM_Kernel, SRM_Kernel)).reshape(3, 7, 5, 5).transpose(2,3,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T09:47:41.012255Z",
     "start_time": "2019-07-27T09:47:40.897291Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "log_device_placement = True\n",
    "# Parameters\n",
    "lr = 0.00003\n",
    "training_iters = 50000000\n",
    "batch_size = 30\n",
    "display_step = 10\n",
    "nb_nontamp_img=16960\n",
    "nb_tamp_img=68355\n",
    "nbFilter=32\n",
    "\n",
    "\n",
    "# LSTM network parameters\n",
    "n_input = 240 # data input (img shape: 64x64)\n",
    "n_steps = 64 # timesteps\n",
    "nBlock=int(math.sqrt(n_steps))\n",
    "n_hidden = 64# hidden layer num of features\n",
    "nStride=int(math.sqrt(n_hidden))\n",
    "# other parameters\n",
    "imSize=256\n",
    "# Network Parameters\n",
    "n_classes = 2 # manipulated vs unmanipulated\n",
    "mx=127.0\n",
    "\n",
    "# tf Graph input\n",
    "input_layer = tf.placeholder(\"float\", [None, imSize,imSize,3])\n",
    "y= tf.placeholder(\"float\", [2,None, imSize,imSize])\n",
    "freqFeat=tf.placeholder(\"float\", [None, 248,248,3])\n",
    "# freqFeat=tf.placeholder(\"float\", [None, 64,240])\n",
    "# freqFeat=tf.placeholder(\"float\", [None, 256,256,3])\n",
    "filter = tf.Variable(tf.random_normal([5,5,3,9]))\n",
    "ratio=15.0 #tf.placeholder(\"float\",[1])\n",
    "#out_rnn=tf.placeholder(\"float\", [None, 128,128,3])\n",
    "# W1 = tf.get_variable('W1', [5,5,3, 10], tf.float32, xavier_initializer())\n",
    "# b1 = tf.Variable(tf.random_normal([5,5,3]))\n",
    "\n",
    "############################################################################\n",
    "#total_layers = 25 #Specify how deep we want our network\n",
    "units_between_stride = 2\n",
    "upsample_factor=16\n",
    "beta=.01\n",
    "outSize=16\n",
    "############################################################################\n",
    "seq = np.linspace(0,63,64).astype(int)\n",
    "order3 = hilbertCurve(3)\n",
    "order3 = np.reshape(order3,(64))\n",
    "print(seq)\n",
    "print(order3)\n",
    "hilbert_ind = np.lexsort((seq,order3))\n",
    "actual_ind=np.lexsort((seq,hilbert_ind))\n",
    "\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([64,64,nbFilter]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([nbFilter]))\n",
    "}\n",
    "\n",
    "atrous_fil = tf.Variable(tf.random_normal([3, 3, 256,256]),name = 'atrous_fil')\n",
    "atrous_fil_1 =tf.Variable(tf.random_normal([3, 3, 256,256]),name ='atrous_fil_1')\n",
    "atrous_fil_2 =tf.Variable(tf.random_normal([3, 3, 256,256]),name ='atrous_fil_2')\n",
    "\n",
    "\n",
    "atrous_fil1 = tf.Variable(tf.random_normal([3, 3, 256,256]),name ='atrous_fil1')\n",
    "atrous_fil2 = tf.Variable(tf.random_normal([3, 3, 256,256]),name ='atrous_fil2')\n",
    "atrous_fil3 = tf.Variable(tf.random_normal([3, 3, 256,256]),name ='atrous_fil3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base-model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T11:35:37.142854Z",
     "start_time": "2019-07-22T11:35:21.470928Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "\n",
    "    def conv_mask_gt(z): \n",
    "        # Get ones for each class instead of a number -- we need that\n",
    "        # for cross-entropy loss later on. Sometimes the groundtruth\n",
    "        # masks have values other than 1 and 0. \n",
    "#         class_labels_tensor = (z==1)\n",
    "#         background_labels_tensor = (z==0)\n",
    "        \n",
    "        class_labels_tensor = (z==1)\n",
    "        background_labels_tensor = (z==0)\n",
    "        # Convert the boolean values into floats -- so that\n",
    "        # computations in cross-entropy loss is correct\n",
    "        bit_mask_class = np.float32(class_labels_tensor)\n",
    "        bit_mask_background = np.float32(background_labels_tensor)\n",
    "        combined_mask=[]\n",
    "        combined_mask.append(bit_mask_background)\n",
    "        combined_mask.append(bit_mask_class)\n",
    "        #combined_mask = tf.concat(concat_dim=3, values=[bit_mask_background,bit_mask_class])\t\t\n",
    "\n",
    "        # Lets reshape our input so that it becomes suitable for \n",
    "        # tf.softmax_cross_entropy_with_logits with [batch_size, num_classes]\n",
    "        #flat_labels = tf.reshape(tensor=combined_mask, shape=(-1, 2))\t\n",
    "        return combined_mask#flat_labels\n",
    "\n",
    "    def get_kernel_size(factor):\n",
    "        #Find the kernel size given the desired factor of upsampling.\n",
    "        return 2 * factor - factor % 2\n",
    "\n",
    "    def upsample_filt(size):\n",
    "        \"\"\"\n",
    "        Make a 2D bilinear kernel suitable for upsampling of the given (h, w) size.\n",
    "        \"\"\"\n",
    "        factor = (size + 1) // 2\n",
    "        if size % 2 == 1:\n",
    "            center = factor - 1\n",
    "        else:\n",
    "            center = factor - 0.5\n",
    "        og = np.ogrid[:size, :size]\n",
    "        return (1 - abs(og[0] - center) / factor) * \\\n",
    "            (1 - abs(og[1] - center) / factor)\n",
    "\n",
    "    def bilinear_upsample_weights(factor, number_of_classes):\n",
    "        \"\"\"\n",
    "        Create weights matrix for transposed convolution with bilinear filter\n",
    "        initialization.\n",
    "        \"\"\"    \n",
    "        filter_size = get_kernel_size(factor)\n",
    "\n",
    "        weights = np.zeros((filter_size,filter_size,number_of_classes,number_of_classes), dtype=np.float32)    \n",
    "        upsample_kernel = upsample_filt(filter_size)    \n",
    "        for i in range(number_of_classes):        \n",
    "            weights[:, :, i, i] = upsample_kernel    \n",
    "        return weights\n",
    "\n",
    "\n",
    "    def resUnit(input_layer,i,nbF):\n",
    "        with tf.variable_scope(\"res_unit\"+str(i)):\n",
    "        #input_layer=tf.reshape(input_layer,[-1,64,64,3])\n",
    "            part1 = slim.batch_norm(input_layer,activation_fn=None)\n",
    "            part2 = tf.nn.relu(part1)\n",
    "            part3 = slim.conv2d(part2,nbF,[3,3],activation_fn=None)\n",
    "            part4 = slim.batch_norm(part3,activation_fn=None)\n",
    "            part5 = tf.nn.relu(part4)\n",
    "            part6 = slim.conv2d(part5,nbF,[3,3],activation_fn=None)\t\n",
    "            output = input_layer + part6\n",
    "            return output\n",
    "\n",
    "    #tf.reset_default_graph()\n",
    "\n",
    "    def segNet(input_layer,bSize,freqFeat,weights,biases):\n",
    "        # layer1: resblock, input size(256,256)\n",
    "        layer1 = slim.conv2d(input_layer,nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(0))\n",
    "        layer1 =resUnit(layer1,1,nbFilter)\n",
    "        layer1 = tf.nn.relu(layer1)\n",
    "        layer2=slim.max_pool2d(layer1, [2, 2], scope='pool_'+str(1))\n",
    "        # layer2: resblock, input size(128,128)   \n",
    "        layer2 = slim.conv2d(layer2,2*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(1))\n",
    "        layer2 =resUnit(layer2,2,2*nbFilter)\n",
    "        layer2 = tf.nn.relu(layer2)\n",
    "        layer3=slim.max_pool2d(layer2, [2, 2], scope='pool_'+str(2))\n",
    "        # layer3: resblock, input size(64,64) \n",
    "        layer3 = slim.conv2d(layer3,4*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(2))\n",
    "        layer3 =resUnit(layer3,3,4*nbFilter)\n",
    "        layer3 = tf.nn.relu(layer3)\n",
    "        layer4=slim.max_pool2d(layer3, [2, 2], scope='pool_'+str(3))\n",
    "        # layer4: resblock, input size(32,32) \n",
    "        layer4 = slim.conv2d(layer4,8*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(3))\n",
    "        layer4 =resUnit(layer4,4,8*nbFilter)\n",
    "        layer4 = tf.nn.relu(layer4)\n",
    "        layer4=slim.max_pool2d(layer4, [2, 2], scope='pool_'+str(4))\n",
    "        # end of layer4: resblock, input size(16,16)\n",
    "\n",
    "        # lstm network \n",
    "        patches=tf.transpose(freqFeat,[1,0,2])\n",
    "        patches=tf.gather(patches,hilbert_ind)\n",
    "        patches=tf.transpose(patches,[1,0,2])         \n",
    "        # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "        xCell=tf.unstack(patches, n_steps, 1)\n",
    "        # 2 stacked layers\n",
    "        stacked_lstm_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(rnn.BasicLSTMCell(n_hidden),output_keep_prob=0.9) for _ in range(2)] )\n",
    "        out, state = rnn.static_rnn(stacked_lstm_cell, xCell, dtype=tf.float32)\n",
    "        # organizing the lstm output\n",
    "        out=tf.gather(out,actual_ind)\n",
    "        # convert to lstm output (64,batchSize,nbFilter)\n",
    "        lstm_out=tf.matmul(out,weights['out'])+biases['out']\n",
    "        print('lstm_out3:',lstm_out.shape)\n",
    "        lstm_out=tf.transpose(lstm_out,[1,0,2])\n",
    "        # convert to size(batchSize, 8,8, nbFilter)\n",
    "        lstm_out=tf.reshape(lstm_out,[bSize,8,8,nbFilter])\n",
    "        # perform batch normalization and activiation\n",
    "        lstm_out=slim.batch_norm(lstm_out,activation_fn=None)\n",
    "        lstm_out=tf.nn.relu(lstm_out)\n",
    "        print('lstm_out3:',lstm_out.shape)\n",
    "        # upsample lstm output to (batchSize, 16,16, nbFilter)\n",
    "        temp=tf.random_normal([bSize,outSize,outSize,nbFilter])\n",
    "        uShape1=tf.shape(temp)\n",
    "        upsample_filter_np = bilinear_upsample_weights(2, nbFilter)\n",
    "        upsample_filter_tensor = tf.constant(upsample_filter_np)\n",
    "        lstm_out = tf.nn.conv2d_transpose(lstm_out, upsample_filter_tensor,output_shape=uShape1,strides=[1, 2, 2, 1])\n",
    "\n",
    "        # reduce the filter size to nbFilter for layer4\n",
    "        top = slim.conv2d(layer4,nbFilter,[1,1], normalizer_fn=slim.batch_norm, activation_fn=None, scope='conv_top')\n",
    "        top = tf.nn.relu(top)\n",
    "        # concatenate both lstm features and image features\n",
    "        joint_out=tf.concat([top,lstm_out],3)\n",
    "        print('joint_out:',joint_out.shape)\n",
    "        \n",
    "        # perform upsampling (batchSize, 64,64, 2*nbFilter)\n",
    "        temp=tf.random_normal([bSize,outSize*4,outSize*4,2*nbFilter])\n",
    "        uShape1=tf.shape(temp)\n",
    "        upsample_filter_np = bilinear_upsample_weights(4, 2*nbFilter)\n",
    "        upsample_filter_tensor = tf.constant(upsample_filter_np)\n",
    "        upsampled_layer4 = tf.nn.conv2d_transpose(joint_out, upsample_filter_tensor,output_shape=uShape1,strides=[1, 4, 4, 1]) \t\n",
    "        print('upsampled_layer4:',upsampled_layer4.shape)\n",
    "        # reduce filter sizes\t\n",
    "        upsampled_layer4 = slim.conv2d(upsampled_layer4,2,[1,1], normalizer_fn=slim.batch_norm, activation_fn=None, scope='conv_'+str(4))\n",
    "        upsampled_layer4=slim.batch_norm(upsampled_layer4,activation_fn=None)\n",
    "        upsampled_layer4=tf.nn.relu(upsampled_layer4)\n",
    "        print('upsampled_layer4:',upsampled_layer4.shape)\n",
    "        # upsampling to (batchSize, 256,256, nbClasses)\n",
    "        temp=tf.random_normal([bSize,outSize*16,outSize*16,2])\n",
    "        uShape1=tf.shape(temp)\n",
    "        upsample_filter_np = bilinear_upsample_weights(4,2)\n",
    "        upsample_filter_tensor = tf.constant(upsample_filter_np)\n",
    "        upsampled_layer5 = tf.nn.conv2d_transpose(upsampled_layer4, upsample_filter_tensor,output_shape=uShape1,strides=[1, 4, 4, 1]) \n",
    "        print('upsampled_layer5:',upsampled_layer5.shape)\n",
    "        #upsampled_layer5=slim.batch_norm(upsampled_layer5,activation_fn=None)\n",
    "        #upsampled_layer5 = slim.conv2d(upsampled_layer5,2,[3,3], normalizer_fn=slim.batch_norm, activation_fn=None, scope='conv_'+str(5))\n",
    "        #upsampled_layer5=tf.nn.relu(upsampled_layer5)\n",
    "\n",
    "\n",
    "        return upsampled_layer5\n",
    "\n",
    "\n",
    "    y1=tf.transpose(y,[1,2,3,0])\n",
    "    upsampled_logits=segNet(input_layer,batch_size,freqFeat,weights,biases)\n",
    "\n",
    "\n",
    "    flat_pred=tf.reshape(upsampled_logits,(-1,n_classes))\n",
    "    flat_y=tf.reshape(y1,(-1,n_classes))\n",
    "\n",
    "    #loss1=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=flat_pred,labels=flat_y))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(flat_y,flat_pred, 1.0))\n",
    "\n",
    "    #all_weights  = tf.trainable_variables()\n",
    "    #regLoss = tf.add_n([ tf.nn.l2_loss(v) for v in all_weights ]) * beta\n",
    "    #loss = 0.75*loss1+loss2\n",
    "    trainer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    update = trainer.minimize(loss)\n",
    "    #update2 = trainer.minimize(loss2)\n",
    "\n",
    "    probabilities=tf.nn.softmax(flat_pred)\n",
    "    correct_pred=tf.equal(tf.argmax(probabilities,1),tf.argmax(flat_y,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "    y_actual=tf.argmax(flat_y,1)\n",
    "    y_pred=tf.argmax(flat_pred,1)\n",
    "\n",
    "    mask_actual= tf.argmax(y1,3)\n",
    "    mask_pred=tf.argmax(upsampled_logits,3)\n",
    "\n",
    "\n",
    "# Initializing the variables\n",
    "# init = tf.initialize_all_variables()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config=tf.ConfigProto()\n",
    "config.allow_soft_placement=True\n",
    "config.log_device_placement=True\n",
    "config.gpu_options.allow_growth=True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PL-GNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T09:48:02.511969Z",
     "start_time": "2019-07-27T09:47:46.805610Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "\n",
    "    def conv_mask_gt(z): \n",
    "        # Get ones for each class instead of a number -- we need that\n",
    "        # for cross-entropy loss later on. Sometimes the groundtruth\n",
    "        # masks have values other than 1 and 0. \n",
    "#         class_labels_tensor = (z==1)\n",
    "#         background_labels_tensor = (z==0)\n",
    "        \n",
    "        class_labels_tensor = (z==1)\n",
    "        background_labels_tensor = (z==0)\n",
    "        # Convert the boolean values into floats -- so that\n",
    "        # computations in cross-entropy loss is correct\n",
    "        bit_mask_class = np.float32(class_labels_tensor)\n",
    "        bit_mask_background = np.float32(background_labels_tensor)\n",
    "        combined_mask=[]\n",
    "        combined_mask.append(bit_mask_background)\n",
    "        combined_mask.append(bit_mask_class)\n",
    "        #combined_mask = tf.concat(concat_dim=3, values=[bit_mask_background,bit_mask_class])\t\t\n",
    "\n",
    "        # Lets reshape our input so that it becomes suitable for \n",
    "        # tf.softmax_cross_entropy_with_logits with [batch_size, num_classes]\n",
    "        #flat_labels = tf.reshape(tensor=combined_mask, shape=(-1, 2))\t\n",
    "        return combined_mask#flat_labels\n",
    "\n",
    "    def get_kernel_size(factor):\n",
    "        #Find the kernel size given the desired factor of upsampling.\n",
    "        return 2 * factor - factor % 2\n",
    "\n",
    "    def upsample_filt(size):\n",
    "        \"\"\"\n",
    "        Make a 2D bilinear kernel suitable for upsampling of the given (h, w) size.\n",
    "        \"\"\"\n",
    "        factor = (size + 1) // 2\n",
    "        if size % 2 == 1:\n",
    "            center = factor - 1\n",
    "        else:\n",
    "            center = factor - 0.5\n",
    "        og = np.ogrid[:size, :size]\n",
    "        return (1 - abs(og[0] - center) / factor) * \\\n",
    "            (1 - abs(og[1] - center) / factor)\n",
    "\n",
    "    def bilinear_upsample_weights(factor, number_of_classes):\n",
    "        \"\"\"\n",
    "        Create weights matrix for transposed convolution with bilinear filter\n",
    "        initialization.\n",
    "        \"\"\"    \n",
    "        filter_size = get_kernel_size(factor)\n",
    "\n",
    "        weights = np.zeros((filter_size,filter_size,number_of_classes,number_of_classes), dtype=np.float32)    \n",
    "        upsample_kernel = upsample_filt(filter_size)    \n",
    "        for i in range(number_of_classes):        \n",
    "            weights[:, :, i, i] = upsample_kernel    \n",
    "        return weights\n",
    "\n",
    "\n",
    "    def resUnit(input_layer,i,nbF):\n",
    "        with tf.variable_scope(\"res_unit\"+str(i)):\n",
    "        #input_layer=tf.reshape(input_layer,[-1,64,64,3])\n",
    "            part1 = slim.batch_norm(input_layer,activation_fn=None)\n",
    "            part2 = tf.nn.relu(part1)\n",
    "            part3 = slim.conv2d(part2,nbF,[3,3],activation_fn=None)\n",
    "            part4 = slim.batch_norm(part3,activation_fn=None)\n",
    "            part5 = tf.nn.relu(part4)\n",
    "            part6 = slim.conv2d(part5,nbF,[3,3],activation_fn=None)\t\n",
    "            output = input_layer + part6\n",
    "            return output\n",
    "\n",
    "    #tf.reset_default_graph()\n",
    "\n",
    "    def segNet(input_layer,bSize,freqFeat,weights,biases):\n",
    "        \n",
    "        # layer1: resblock, input size(256,256)\n",
    "        layer1 = tf.nn.conv2d(input_layer, SRM_Kernel, strides=[1,1,1,1],padding ='SAME',name = 'SRM_out' )\n",
    "        layer2 = tf.nn.conv2d(input_layer, filter, strides=[1,1,1,1],padding ='SAME',name = 'SRM_out1' )\n",
    "        concat = tf.concat([layer1, layer2], axis=3, name='concat')\n",
    "        print('concat:',concat.shape)\n",
    "        \n",
    "        Conv_1 = slim.conv2d(concat,nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(1))\n",
    "        ReLu_1 = tf.nn.relu(Conv_1)\n",
    "        Pool_1 = slim.max_pool2d(ReLu_1, [2, 2], scope='pool_'+str(1))\n",
    "        print('Pool_1:',Pool_1.shape)\n",
    "        \n",
    "        # layer2: resblock, input size(128,128)   \n",
    "        Conv_2 = slim.conv2d(Pool_1,2*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(2))\n",
    "        ReLu_2 = tf.nn.relu(Conv_2)\n",
    "        Conv_3 = slim.conv2d(ReLu_2,2*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(3))\n",
    "        ReLu_3 = tf.nn.relu(Conv_3)\n",
    "        Pool_2 = slim.max_pool2d(ReLu_3, [2, 2], scope='pool_'+str(2))\n",
    "        print('Pool_2:',Pool_2.shape)\n",
    "        \n",
    "        # layer3: resblock, input size(64,64) \n",
    "        Conv_4 = slim.conv2d(Pool_2,4*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(4))\n",
    "        ReLu_4 = tf.nn.relu(Conv_4)\n",
    "        Conv_5 = slim.conv2d(ReLu_4,4*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(5))\n",
    "        ReLu_5 = tf.nn.relu(Conv_5)\n",
    "        Conv_6 = slim.conv2d(ReLu_5,4*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(6))\n",
    "        ReLu_6 = tf.nn.relu(Conv_6)\n",
    "        Pool_3 = slim.max_pool2d(ReLu_6, [2, 2], scope='pool_'+str(3))\n",
    "        # layer4: resblock, input size(32,32) \n",
    "        print('Pool_3:',Pool_3.shape)\n",
    "        \n",
    "        Conv_7 = slim.conv2d(Pool_3,8*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(7))\n",
    "        ReLu_7= tf.nn.relu(Conv_7)\n",
    "        Conv_8 = slim.conv2d(ReLu_7,8*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(8))\n",
    "        ReLu_8 = tf.nn.relu(Conv_8)\n",
    "        Conv_9 = slim.conv2d(ReLu_8,8*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(9))\n",
    "        ReLu_9 = tf.nn.relu(Conv_9)\n",
    "        print('ReLu_9:',ReLu_9.shape)\n",
    "        # layer4: resblock, input size(32,32) \n",
    "        \n",
    "        Conv_11_AC = tf.nn.atrous_conv2d(ReLu_9,atrous_fil,rate =2,padding = 'SAME',name = 'conv_'+str(11))\n",
    "        BN_2 = slim.batch_norm(Conv_11_AC,activation_fn=None)\n",
    "        Tan_2 = tf.nn.relu(BN_2)\n",
    "        Conv_12_AC = tf.nn.atrous_conv2d(Tan_2,atrous_fil_1,rate =2,padding = 'SAME',name = 'conv_'+str(12))\n",
    "        BN_3 = slim.batch_norm(Conv_12_AC,activation_fn=None)\n",
    "        Tan_3 = tf.nn.relu(BN_3)\n",
    "        Conv_13_AC = tf.nn.atrous_conv2d(Tan_3,atrous_fil_2,rate =2,padding = 'SAME',name = 'conv_'+str(13))\n",
    "        BN_4 = slim.batch_norm(Conv_13_AC,activation_fn=None)\n",
    "        Tan_4 = tf.nn.relu(BN_4)\n",
    "        output = ReLu_9 + Tan_4\n",
    "#         output = slim.max_pool2d(output, [2, 2], scope='pool_'+str(4))\n",
    "             \n",
    "        layer6 = slim.conv2d(output,8*nbFilter,[1,1],normalizer_fn=slim.batch_norm,scope='conv_'+str(14))\n",
    "        layer6 = tf.nn.relu(layer6)\n",
    "       \n",
    "                                      \n",
    "        layer7 = tf.nn.atrous_conv2d(output,atrous_fil1,rate = 3,padding = 'SAME',name='conv_'+str(15))\n",
    "        layer7 = tf.nn.relu(layer7)\n",
    "        \n",
    "                                      \n",
    "        layer8 = tf.nn.atrous_conv2d(output,atrous_fil2,rate = 5,padding = 'SAME',name='conv_'+str(16))\n",
    "        layer8 = tf.nn.relu(layer8)\n",
    "        \n",
    "                                      \n",
    "        layer9 = tf.nn.atrous_conv2d(output,atrous_fil3,rate = 7,padding = 'SAME',name='conv_'+str(17))\n",
    "        layer9 = tf.nn.relu(layer9)\n",
    "       \n",
    "        \n",
    "        layer10 = layer6+layer7+layer8+layer9\n",
    "        print('layer10:',layer10.shape)\n",
    "        \n",
    "        layer12 = tf.nn.relu(layer10)\n",
    "        layer13 = slim.max_pool2d(layer12, [2, 2], scope='pool_'+str(4))\n",
    "        print('layer13:',layer13.shape)\n",
    "     \n",
    "        # lstm network \n",
    "        layer55 = slim.conv2d(freqFeat,16,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(18))\n",
    "        layer55 = tf.nn.relu(layer55)\n",
    "        layer66 = slim.conv2d(layer55,1,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(19))\n",
    "        layer66 = tf.nn.relu(layer66)\n",
    "        print('layer6_shape:',layer66.shape)  # ( bs, 256, 256, 1)\n",
    "        \n",
    "        layer77=tf.transpose(layer66,[0,3,1,2])\n",
    "        print('layer7_shape:',layer77.shape)  # ( bs, 256, 256, 1)\n",
    "        \n",
    "        y_list = tf.split(layer77,8,axis=3)\n",
    "        print('y_list_shape2:',len(y_list))\n",
    "        xy_list = [tf.split(x,8,axis =2) for x in y_list] ##\n",
    "        print('xy_list_shape2:',len(xy_list))\n",
    "        xy = [item for items in xy_list for item in items]\n",
    "        print('xy_shape:',len(xy))\n",
    "#         xy = torch.cat(xy,1)\n",
    "        xy = tf.concat(xy,1)\n",
    "        print('xy_shape2:',xy.shape)\n",
    "#         patches = xy.view(-1,64,64)#\n",
    "        patches = tf.reshape(xy,(-1,64,31*31))\n",
    "        print('patches_shape2:',patches.shape)\n",
    "        \n",
    "        \n",
    "#         patches=tf.transpose(freqFeat,[1,0,2])\n",
    "#         patches=tf.gather(patches,hilbert_ind)\n",
    "#         patches=tf.transpose(patches,[1,0,2])\n",
    "#         print('patches:',patches.shape)\n",
    "        # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "        xCell=tf.unstack(patches, n_steps, 1)\n",
    "        # 2 stacked layers\n",
    "        stacked_lstm_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(rnn.BasicLSTMCell(n_hidden),output_keep_prob=0.9) for _ in range(2)] )\n",
    "        out, state = rnn.static_rnn(stacked_lstm_cell, xCell, dtype=tf.float32)\n",
    "        # organizing the lstm output\n",
    "        out=tf.gather(out,actual_ind)\n",
    "        # convert to lstm output (64,batchSize,nbFilter)\n",
    "        lstm_out=tf.matmul(out,weights['out'])+biases['out']\n",
    "        print('lstm_out1:',lstm_out.shape)\n",
    "        lstm_out=tf.transpose(lstm_out,[1,0,2])\n",
    "        print('lstm_out2:',lstm_out.shape)\n",
    "        \n",
    "        # convert to size(batchSize, 8,8, nbFilter)\n",
    "        lstm_out=tf.reshape(lstm_out,[bSize,8,8,nbFilter])\n",
    "        # perform batch normalization and activiation\n",
    "        lstm_out=slim.batch_norm(lstm_out,activation_fn=None)\n",
    "        lstm_out=tf.nn.relu(lstm_out)\n",
    "        print('lstm_out3:',lstm_out.shape)\n",
    "        # upsample lstm output to (batchSize, 16,16, nbFilter)\n",
    "        temp=tf.random_normal([bSize,outSize,outSize,nbFilter])\n",
    "        uShape1=tf.shape(temp)\n",
    "        upsample_filter_np = bilinear_upsample_weights(2, nbFilter)\n",
    "        upsample_filter_tensor = tf.constant(upsample_filter_np)\n",
    "        lstm_out = tf.nn.conv2d_transpose(lstm_out, upsample_filter_tensor,output_shape=uShape1,strides=[1, 2, 2, 1])\n",
    "        print('lstm_out4:',lstm_out.shape)\n",
    "        # reduce the filter size to nbFilter for layer4\n",
    "        top = slim.conv2d(layer13,nbFilter,[1,1], normalizer_fn=slim.batch_norm, activation_fn=None, scope='conv_top')\n",
    "        top = tf.nn.relu(top)\n",
    "        print('top:',top.shape)\n",
    "        # concatenate both lstm features and image features\n",
    "        joint_out=tf.concat([top,lstm_out],3)\n",
    "        print('joint_out:',joint_out.shape)\n",
    "        # perform upsampling (batchSize, 64,64, 2*nbFilter)\n",
    "        temp=tf.random_normal([bSize,outSize*4,outSize*4,2*nbFilter])\n",
    "        uShape1=tf.shape(temp)\n",
    "        upsample_filter_np = bilinear_upsample_weights(4, 2*nbFilter)\n",
    "        upsample_filter_tensor = tf.constant(upsample_filter_np)\n",
    "        upsampled_layer4 = tf.nn.conv2d_transpose(joint_out, upsample_filter_tensor,output_shape=uShape1,strides=[1, 4, 4, 1]) \t\n",
    "        # reduce filter sizes\t\n",
    "        upsampled_layer4 = slim.conv2d(upsampled_layer4,2,[1,1], normalizer_fn=slim.batch_norm, activation_fn=None, scope='conv_'+str(12))\n",
    "        upsampled_layer4=slim.batch_norm(upsampled_layer4,activation_fn=None)\n",
    "        upsampled_layer4=tf.nn.relu(upsampled_layer4)\n",
    "        # upsampling to (batchSize, 256,256, nbClasses)\n",
    "        temp=tf.random_normal([bSize,outSize*16,outSize*16,2])\n",
    "        uShape1=tf.shape(temp)\n",
    "        upsample_filter_np = bilinear_upsample_weights(4,2)\n",
    "        upsample_filter_tensor = tf.constant(upsample_filter_np)\n",
    "        upsampled_layer5 = tf.nn.conv2d_transpose(upsampled_layer4, upsample_filter_tensor,output_shape=uShape1,strides=[1, 4, 4, 1]) \n",
    "        #upsampled_layer5=slim.batch_norm(upsampled_layer5,activation_fn=None)\n",
    "        #upsampled_layer5 = slim.conv2d(upsampled_layer5,2,[3,3], normalizer_fn=slim.batch_norm, activation_fn=None, scope='conv_'+str(5))\n",
    "        #upsampled_layer5=tf.nn.relu(upsampled_layer5)\n",
    "\n",
    "\n",
    "        return upsampled_layer5\n",
    "\n",
    "\n",
    "    y1=tf.transpose(y,[1,2,3,0])\n",
    "    upsampled_logits=segNet(input_layer,batch_size,freqFeat,weights,biases)\n",
    "    print('upsampled_logits_shape:',upsampled_logits.shape)\n",
    "\n",
    "    flat_pred=tf.reshape(upsampled_logits,(-1,n_classes))\n",
    "    print('flat_pred_shape:',flat_pred.shape)\n",
    "    \n",
    "    flat_y=tf.reshape(y1,(-1,n_classes))\n",
    "\n",
    "    #loss1=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=flat_pred,labels=flat_y))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(flat_y,flat_pred, 1.0))\n",
    "\n",
    "    #all_weights  = tf.trainable_variables()\n",
    "    #regLoss = tf.add_n([ tf.nn.l2_loss(v) for v in all_weights ]) * beta\n",
    "    #loss = 0.75*loss1+loss2\n",
    "    trainer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    update = trainer.minimize(loss)\n",
    "    #update2 = trainer.minimize(loss2)\n",
    "\n",
    "    probabilities=tf.nn.softmax(flat_pred)\n",
    "    correct_pred=tf.equal(tf.argmax(probabilities,1),tf.argmax(flat_y,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "    y_actual=tf.argmax(flat_y,1)\n",
    "    y_pred=tf.argmax(flat_pred,1)\n",
    "\n",
    "    mask_actual= tf.argmax(y1,3)\n",
    "    mask_pred=tf.argmax(upsampled_logits,3)\n",
    "\n",
    "\n",
    "# Initializing the variables\n",
    "# init = tf.initialize_all_variables()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config=tf.ConfigProto()\n",
    "config.allow_soft_placement=True\n",
    "config.log_device_placement=True\n",
    "config.gpu_options.allow_growth=True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PL-GNet_no_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T07:04:52.247601Z",
     "start_time": "2019-07-25T07:04:50.389675Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "\n",
    "    def conv_mask_gt(z): \n",
    "        # Get ones for each class instead of a number -- we need that\n",
    "        # for cross-entropy loss later on. Sometimes the groundtruth\n",
    "        # masks have values other than 1 and 0. \n",
    "#         class_labels_tensor = (z==1)\n",
    "#         background_labels_tensor = (z==0)\n",
    "        \n",
    "        class_labels_tensor = (z==1)\n",
    "        background_labels_tensor = (z==0)\n",
    "        # Convert the boolean values into floats -- so that\n",
    "        # computations in cross-entropy loss is correct\n",
    "        bit_mask_class = np.float32(class_labels_tensor)\n",
    "        bit_mask_background = np.float32(background_labels_tensor)\n",
    "        combined_mask=[]\n",
    "        combined_mask.append(bit_mask_background)\n",
    "        combined_mask.append(bit_mask_class)\n",
    "        #combined_mask = tf.concat(concat_dim=3, values=[bit_mask_background,bit_mask_class])\t\t\n",
    "\n",
    "        # Lets reshape our input so that it becomes suitable for \n",
    "        # tf.softmax_cross_entropy_with_logits with [batch_size, num_classes]\n",
    "        #flat_labels = tf.reshape(tensor=combined_mask, shape=(-1, 2))\t\n",
    "        return combined_mask#flat_labels\n",
    "\n",
    "    def get_kernel_size(factor):\n",
    "        #Find the kernel size given the desired factor of upsampling.\n",
    "        return 2 * factor - factor % 2\n",
    "\n",
    "    def upsample_filt(size):\n",
    "        \"\"\"\n",
    "        Make a 2D bilinear kernel suitable for upsampling of the given (h, w) size.\n",
    "        \"\"\"\n",
    "        factor = (size + 1) // 2\n",
    "        if size % 2 == 1:\n",
    "            center = factor - 1\n",
    "        else:\n",
    "            center = factor - 0.5\n",
    "        og = np.ogrid[:size, :size]\n",
    "        return (1 - abs(og[0] - center) / factor) * \\\n",
    "            (1 - abs(og[1] - center) / factor)\n",
    "\n",
    "    def bilinear_upsample_weights(factor, number_of_classes):\n",
    "        \"\"\"\n",
    "        Create weights matrix for transposed convolution with bilinear filter\n",
    "        initialization.\n",
    "        \"\"\"    \n",
    "        filter_size = get_kernel_size(factor)\n",
    "\n",
    "        weights = np.zeros((filter_size,filter_size,number_of_classes,number_of_classes), dtype=np.float32)    \n",
    "        upsample_kernel = upsample_filt(filter_size)    \n",
    "        for i in range(number_of_classes):        \n",
    "            weights[:, :, i, i] = upsample_kernel    \n",
    "        return weights\n",
    "\n",
    "\n",
    "    def resUnit(input_layer,i,nbF):\n",
    "        with tf.variable_scope(\"res_unit\"+str(i)):\n",
    "        #input_layer=tf.reshape(input_layer,[-1,64,64,3])\n",
    "            part1 = slim.batch_norm(input_layer,activation_fn=None)\n",
    "            part2 = tf.nn.relu(part1)\n",
    "            part3 = slim.conv2d(part2,nbF,[3,3],activation_fn=None)\n",
    "            part4 = slim.batch_norm(part3,activation_fn=None)\n",
    "            part5 = tf.nn.relu(part4)\n",
    "            part6 = slim.conv2d(part5,nbF,[3,3],activation_fn=None)\t\n",
    "            output = input_layer + part6\n",
    "            return output\n",
    "\n",
    "    #tf.reset_default_graph()\n",
    "\n",
    "    def segNet(input_layer,bSize,freqFeat,weights,biases):\n",
    "        \n",
    "        # layer1: resblock, input size(256,256)\n",
    "        layer1 = tf.nn.conv2d(input_layer, Bayar_Kernel, strides=[1,1,1,1],padding ='SAME',name = 'SRM_out' )\n",
    "        layer2 = tf.nn.conv2d(input_layer, filter, strides=[1,1,1,1],padding ='SAME',name = 'SRM_out1' )\n",
    "        layer3 = tf.nn.conv2d(input_layer, SRM_Kernel, strides=[1,1,1,1],padding ='SAME',name = 'SRM_out1' )\n",
    "        concat = tf.concat([layer1, layer2,layer3], axis=3, name='concat')\n",
    "        print('concat:',concat.shape)\n",
    "        \n",
    "        Conv_1 = slim.conv2d(concat,nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(1))\n",
    "        ReLu_1 = tf.nn.relu(Conv_1)\n",
    "        Pool_1 = slim.max_pool2d(ReLu_1, [2, 2], scope='pool_'+str(1))\n",
    "        print('Pool_1:',Pool_1.shape)\n",
    "        \n",
    "        # layer2: resblock, input size(128,128)   \n",
    "        Conv_2 = slim.conv2d(Pool_1,2*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(2))\n",
    "        ReLu_2 = tf.nn.relu(Conv_2)\n",
    "        Conv_3 = slim.conv2d(ReLu_2,2*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(3))\n",
    "        ReLu_3 = tf.nn.relu(Conv_3)\n",
    "        Pool_2 = slim.max_pool2d(ReLu_3, [2, 2], scope='pool_'+str(2))\n",
    "        print('Pool_2:',Pool_2.shape)\n",
    "        \n",
    "        # layer3: resblock, input size(64,64) \n",
    "        Conv_4 = slim.conv2d(Pool_2,4*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(4))\n",
    "        ReLu_4 = tf.nn.relu(Conv_4)\n",
    "        Conv_5 = slim.conv2d(ReLu_4,4*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(5))\n",
    "        ReLu_5 = tf.nn.relu(Conv_5)\n",
    "        Conv_6 = slim.conv2d(ReLu_5,4*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(6))\n",
    "        ReLu_6 = tf.nn.relu(Conv_6)\n",
    "        Pool_3 = slim.max_pool2d(ReLu_6, [2, 2], scope='pool_'+str(3))\n",
    "        # layer4: resblock, input size(32,32) \n",
    "        print('Pool_3:',Pool_3.shape)\n",
    "        \n",
    "        Conv_7 = slim.conv2d(Pool_3,8*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(7))\n",
    "        ReLu_7= tf.nn.relu(Conv_7)\n",
    "        Conv_8 = slim.conv2d(ReLu_7,8*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(8))\n",
    "        ReLu_8 = tf.nn.relu(Conv_8)\n",
    "        Conv_9 = slim.conv2d(ReLu_8,8*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(9))\n",
    "        ReLu_9 = tf.nn.relu(Conv_9)\n",
    "        print('ReLu_9:',ReLu_9.shape)\n",
    "        # layer4: resblock, input size(32,32) \n",
    "#         print('Pool_4:',Pool_4.shape)\n",
    "        \n",
    "#         Conv_10_AC = slim.conv2d(ReLu_9,8*nbFilter,[1,1],normalizer_fn=slim.batch_norm,scope='conv_'+str(10))\n",
    "#         Tan_1 = tf.nn.relu(Conv_10_AC)\n",
    "        \n",
    "        Conv_11_AC = tf.nn.atrous_conv2d(ReLu_9,atrous_fil,rate =2,padding = 'SAME',name = 'conv_'+str(11))\n",
    "        BN_2 = slim.batch_norm(Conv_11_AC,activation_fn=None)\n",
    "        Tan_2 = tf.nn.relu(BN_2)\n",
    "        Conv_12_AC = tf.nn.atrous_conv2d(Tan_2,atrous_fil_1,rate =2,padding = 'SAME',name = 'conv_'+str(12))\n",
    "        BN_3 = slim.batch_norm(Conv_12_AC,activation_fn=None)\n",
    "        Tan_3 = tf.nn.relu(BN_3)\n",
    "        Conv_13_AC = tf.nn.atrous_conv2d(Tan_3,atrous_fil_2,rate =2,padding = 'SAME',name = 'conv_'+str(13))\n",
    "        BN_4 = slim.batch_norm(Conv_13_AC,activation_fn=None)\n",
    "        Tan_4 = tf.nn.relu(BN_4)\n",
    "        output = ReLu_9 + Tan_4\n",
    "#         output = slim.max_pool2d(output, [2, 2], scope='pool_'+str(4))\n",
    "        \n",
    "#         layer55 = tf.nn.relu(output)\n",
    "       \n",
    "        layer6 = slim.conv2d(output,8*nbFilter,[1,1],normalizer_fn=slim.batch_norm,scope='conv_'+str(14))\n",
    "        layer6 = tf.nn.relu(layer6)\n",
    "       \n",
    "                                      \n",
    "        layer7 = tf.nn.atrous_conv2d(output,atrous_fil1,rate = 3,padding = 'SAME',name='conv_'+str(15))\n",
    "        layer7 = tf.nn.relu(layer7)\n",
    "        \n",
    "                                      \n",
    "        layer8 = tf.nn.atrous_conv2d(output,atrous_fil2,rate = 5,padding = 'SAME',name='conv_'+str(16))\n",
    "        layer8 = tf.nn.relu(layer8)\n",
    "        \n",
    "                                      \n",
    "        layer9 = tf.nn.atrous_conv2d(output,atrous_fil3,rate = 7,padding = 'SAME',name='conv_'+str(17))\n",
    "        layer9 = tf.nn.relu(layer9)\n",
    "       \n",
    "        \n",
    "        layer10 = layer6+layer7+layer8+layer9\n",
    "        print('layer10:',layer10.shape)\n",
    "        \n",
    "        layer12 = tf.nn.relu(layer10)\n",
    "        layer13 = slim.max_pool2d(layer12, [2, 2], scope='pool_'+str(4))\n",
    "        print('layer13:',layer13.shape)\n",
    "     \n",
    "#         # lstm network \n",
    "#         layer55 = slim.conv2d(freqFeat,16,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(18))\n",
    "#         layer55 = tf.nn.relu(layer55)\n",
    "#         layer66 = slim.conv2d(layer55,1,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(19))\n",
    "#         layer66 = tf.nn.relu(layer66)\n",
    "#         print('layer6_shape:',layer66.shape)  # ( bs, 256, 256, 1)\n",
    "        \n",
    "#         layer77=tf.transpose(layer66,[0,3,1,2])\n",
    "#         print('layer7_shape:',layer77.shape)  # ( bs, 256, 256, 1)\n",
    "        \n",
    "#         y_list = tf.split(layer77,8,axis=3)\n",
    "#         print('y_list_shape2:',len(y_list))\n",
    "#         xy_list = [tf.split(x,8,axis =2) for x in y_list] ##\n",
    "#         print('xy_list_shape2:',len(xy_list))\n",
    "#         xy = [item for items in xy_list for item in items]\n",
    "#         print('xy_shape:',len(xy))\n",
    "# #         xy = torch.cat(xy,1)\n",
    "#         xy = tf.concat(xy,1)\n",
    "#         print('xy_shape2:',xy.shape)\n",
    "# #         patches = xy.view(-1,64,64)#\n",
    "#         patches = tf.reshape(xy,(-1,64,31*31))\n",
    "#         print('patches_shape2:',patches.shape)\n",
    "        \n",
    "        \n",
    "# #         patches=tf.transpose(freqFeat,[1,0,2])\n",
    "# #         patches=tf.gather(patches,hilbert_ind)\n",
    "# #         patches=tf.transpose(patches,[1,0,2])\n",
    "# #         print('patches:',patches.shape)\n",
    "#         # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "#         xCell=tf.unstack(patches, n_steps, 1)\n",
    "#         # 2 stacked layers\n",
    "#         stacked_lstm_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(rnn.BasicLSTMCell(n_hidden),output_keep_prob=0.9) for _ in range(2)] )\n",
    "#         out, state = rnn.static_rnn(stacked_lstm_cell, xCell, dtype=tf.float32)\n",
    "#         # organizing the lstm output\n",
    "#         out=tf.gather(out,actual_ind)\n",
    "#         # convert to lstm output (64,batchSize,nbFilter)\n",
    "#         lstm_out=tf.matmul(out,weights['out'])+biases['out']\n",
    "#         print('lstm_out1:',lstm_out.shape)\n",
    "#         lstm_out=tf.transpose(lstm_out,[1,0,2])\n",
    "#         print('lstm_out2:',lstm_out.shape)\n",
    "        \n",
    "#         # convert to size(batchSize, 8,8, nbFilter)\n",
    "#         lstm_out=tf.reshape(lstm_out,[bSize,8,8,nbFilter])\n",
    "#         # perform batch normalization and activiation\n",
    "#         lstm_out=slim.batch_norm(lstm_out,activation_fn=None)\n",
    "#         lstm_out=tf.nn.relu(lstm_out)\n",
    "#         print('lstm_out3:',lstm_out.shape)\n",
    "#         # upsample lstm output to (batchSize, 16,16, nbFilter)\n",
    "#         temp=tf.random_normal([bSize,outSize,outSize,nbFilter])\n",
    "#         uShape1=tf.shape(temp)\n",
    "#         upsample_filter_np = bilinear_upsample_weights(2, nbFilter)\n",
    "#         upsample_filter_tensor = tf.constant(upsample_filter_np)\n",
    "#         lstm_out = tf.nn.conv2d_transpose(lstm_out, upsample_filter_tensor,output_shape=uShape1,strides=[1, 2, 2, 1])\n",
    "#         print('lstm_out4:',lstm_out.shape)\n",
    "        # reduce the filter size to nbFilter for layer4\n",
    "        top = slim.conv2d(layer13,2*nbFilter,[1,1], normalizer_fn=slim.batch_norm, activation_fn=None, scope='conv_top')\n",
    "        top = tf.nn.relu(top)\n",
    "        print('top:',top.shape)\n",
    "        # concatenate both lstm features and image features\n",
    "#         joint_out=tf.concat([top,lstm_out],3)\n",
    "#         print('joint_out:',joint_out.shape)\n",
    "        # perform upsampling (batchSize, 64,64, 2*nbFilter)\n",
    "        temp=tf.random_normal([bSize,outSize*4,outSize*4,2*nbFilter])\n",
    "        uShape1=tf.shape(temp)\n",
    "        upsample_filter_np = bilinear_upsample_weights(4, 2*nbFilter)\n",
    "        upsample_filter_tensor = tf.constant(upsample_filter_np)\n",
    "        upsampled_layer4 = tf.nn.conv2d_transpose(top, upsample_filter_tensor,output_shape=uShape1,strides=[1, 4, 4, 1]) \t\n",
    "        # reduce filter sizes\t\n",
    "        upsampled_layer4 = slim.conv2d(upsampled_layer4,2,[1,1], normalizer_fn=slim.batch_norm, activation_fn=None, scope='conv_'+str(12))\n",
    "        upsampled_layer4=slim.batch_norm(upsampled_layer4,activation_fn=None)\n",
    "        upsampled_layer4=tf.nn.relu(upsampled_layer4)\n",
    "        # upsampling to (batchSize, 256,256, nbClasses)\n",
    "        temp=tf.random_normal([bSize,outSize*16,outSize*16,2])\n",
    "        uShape1=tf.shape(temp)\n",
    "        upsample_filter_np = bilinear_upsample_weights(4,2)\n",
    "        upsample_filter_tensor = tf.constant(upsample_filter_np)\n",
    "        upsampled_layer5 = tf.nn.conv2d_transpose(upsampled_layer4, upsample_filter_tensor,output_shape=uShape1,strides=[1, 4, 4, 1]) \n",
    "        #upsampled_layer5=slim.batch_norm(upsampled_layer5,activation_fn=None)\n",
    "        #upsampled_layer5 = slim.conv2d(upsampled_layer5,2,[3,3], normalizer_fn=slim.batch_norm, activation_fn=None, scope='conv_'+str(5))\n",
    "        #upsampled_layer5=tf.nn.relu(upsampled_layer5)\n",
    "\n",
    "\n",
    "        return upsampled_layer5\n",
    "\n",
    "\n",
    "    y1=tf.transpose(y,[1,2,3,0])\n",
    "    upsampled_logits=segNet(input_layer,batch_size,freqFeat,weights,biases)\n",
    "    print('upsampled_logits_shape:',upsampled_logits.shape)\n",
    "\n",
    "    flat_pred=tf.reshape(upsampled_logits,(-1,n_classes))\n",
    "    print('flat_pred_shape:',flat_pred.shape)\n",
    "    \n",
    "    flat_y=tf.reshape(y1,(-1,n_classes))\n",
    "\n",
    "    #loss1=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=flat_pred,labels=flat_y))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(flat_y,flat_pred, 1.0))\n",
    "\n",
    "    #all_weights  = tf.trainable_variables()\n",
    "    #regLoss = tf.add_n([ tf.nn.l2_loss(v) for v in all_weights ]) * beta\n",
    "    #loss = 0.75*loss1+loss2\n",
    "    trainer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    update = trainer.minimize(loss)\n",
    "    #update2 = trainer.minimize(loss2)\n",
    "\n",
    "    probabilities=tf.nn.softmax(flat_pred)\n",
    "    correct_pred=tf.equal(tf.argmax(probabilities,1),tf.argmax(flat_y,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "    y_actual=tf.argmax(flat_y,1)\n",
    "    y_pred=tf.argmax(flat_pred,1)\n",
    "\n",
    "    mask_actual= tf.argmax(y1,3)\n",
    "    mask_pred=tf.argmax(upsampled_logits,3)\n",
    "\n",
    "\n",
    "# Initializing the variables\n",
    "# init = tf.initialize_all_variables()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config=tf.ConfigProto()\n",
    "config.allow_soft_placement=True\n",
    "config.log_device_placement=True\n",
    "config.gpu_options.allow_growth=True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PL-GNet+original-feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:29:43.529434Z",
     "start_time": "2019-06-23T13:29:16.352405Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "\n",
    "    def conv_mask_gt(z): \n",
    "        # Get ones for each class instead of a number -- we need that\n",
    "        # for cross-entropy loss later on. Sometimes the groundtruth\n",
    "        # masks have values other than 1 and 0. \n",
    "#         class_labels_tensor = (z==1)\n",
    "#         background_labels_tensor = (z==0)\n",
    "        \n",
    "        class_labels_tensor = (z==1)\n",
    "        background_labels_tensor = (z==0)\n",
    "        # Convert the boolean values into floats -- so that\n",
    "        # computations in cross-entropy loss is correct\n",
    "        bit_mask_class = np.float32(class_labels_tensor)\n",
    "        bit_mask_background = np.float32(background_labels_tensor)\n",
    "        combined_mask=[]\n",
    "        combined_mask.append(bit_mask_background)\n",
    "        combined_mask.append(bit_mask_class)\n",
    "        #combined_mask = tf.concat(concat_dim=3, values=[bit_mask_background,bit_mask_class])\t\t\n",
    "\n",
    "        # Lets reshape our input so that it becomes suitable for \n",
    "        # tf.softmax_cross_entropy_with_logits with [batch_size, num_classes]\n",
    "        #flat_labels = tf.reshape(tensor=combined_mask, shape=(-1, 2))\t\n",
    "        return combined_mask#flat_labels\n",
    "\n",
    "    def get_kernel_size(factor):\n",
    "        #Find the kernel size given the desired factor of upsampling.\n",
    "        return 2 * factor - factor % 2\n",
    "\n",
    "    def upsample_filt(size):\n",
    "        \"\"\"\n",
    "        Make a 2D bilinear kernel suitable for upsampling of the given (h, w) size.\n",
    "        \"\"\"\n",
    "        factor = (size + 1) // 2\n",
    "        if size % 2 == 1:\n",
    "            center = factor - 1\n",
    "        else:\n",
    "            center = factor - 0.5\n",
    "        og = np.ogrid[:size, :size]\n",
    "        return (1 - abs(og[0] - center) / factor) * \\\n",
    "            (1 - abs(og[1] - center) / factor)\n",
    "\n",
    "    def bilinear_upsample_weights(factor, number_of_classes):\n",
    "        \"\"\"\n",
    "        Create weights matrix for transposed convolution with bilinear filter\n",
    "        initialization.\n",
    "        \"\"\"    \n",
    "        filter_size = get_kernel_size(factor)\n",
    "\n",
    "        weights = np.zeros((filter_size,filter_size,number_of_classes,number_of_classes), dtype=np.float32)    \n",
    "        upsample_kernel = upsample_filt(filter_size)    \n",
    "        for i in range(number_of_classes):        \n",
    "            weights[:, :, i, i] = upsample_kernel    \n",
    "        return weights\n",
    "\n",
    "\n",
    "    def resUnit(input_layer,i,nbF):\n",
    "        with tf.variable_scope(\"res_unit\"+str(i)):\n",
    "        #input_layer=tf.reshape(input_layer,[-1,64,64,3])\n",
    "            part1 = slim.batch_norm(input_layer,activation_fn=None)\n",
    "            part2 = tf.nn.relu(part1)\n",
    "            part3 = slim.conv2d(part2,nbF,[3,3],activation_fn=None)\n",
    "            part4 = slim.batch_norm(part3,activation_fn=None)\n",
    "            part5 = tf.nn.relu(part4)\n",
    "            part6 = slim.conv2d(part5,nbF,[3,3],activation_fn=None)\t\n",
    "            output = input_layer + part6\n",
    "            return output\n",
    "\n",
    "    #tf.reset_default_graph()\n",
    "\n",
    "    def segNet(input_layer,bSize,freqFeat,weights,biases):\n",
    "        \n",
    "        # layer1: resblock, input size(256,256)\n",
    "        layer1 = tf.nn.conv2d(input_layer, SRM_Kernel, strides=[1,1,1,1],padding ='SAME',name = 'SRM_out' )\n",
    "        layer2 = tf.nn.conv2d(input_layer, filter, strides=[1,1,1,1],padding ='SAME',name = 'SRM_out1' )\n",
    "        concat = tf.concat([layer1, layer2], axis=3, name='concat')\n",
    "        print('concat:',concat.shape)\n",
    "        \n",
    "        Conv_1 = slim.conv2d(concat,nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(1))\n",
    "        ReLu_1 = tf.nn.relu(Conv_1)\n",
    "        Pool_1 = slim.max_pool2d(ReLu_1, [2, 2], scope='pool_'+str(1))\n",
    "        print('Pool_1:',Pool_1.shape)\n",
    "        \n",
    "        # layer2: resblock, input size(128,128)   \n",
    "        Conv_2 = slim.conv2d(Pool_1,2*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(2))\n",
    "        ReLu_2 = tf.nn.relu(Conv_2)\n",
    "        Conv_3 = slim.conv2d(ReLu_2,2*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(3))\n",
    "        ReLu_3 = tf.nn.relu(Conv_3)\n",
    "        Pool_2 = slim.max_pool2d(ReLu_3, [2, 2], scope='pool_'+str(2))\n",
    "        print('Pool_2:',Pool_2.shape)\n",
    "        \n",
    "        # layer3: resblock, input size(64,64) \n",
    "        Conv_4 = slim.conv2d(Pool_2,4*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(4))\n",
    "        ReLu_4 = tf.nn.relu(Conv_4)\n",
    "        Conv_5 = slim.conv2d(ReLu_4,4*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(5))\n",
    "        ReLu_5 = tf.nn.relu(Conv_5)\n",
    "        Conv_6 = slim.conv2d(ReLu_5,4*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(6))\n",
    "        ReLu_6 = tf.nn.relu(Conv_6)\n",
    "        Pool_3 = slim.max_pool2d(ReLu_6, [2, 2], scope='pool_'+str(3))\n",
    "        # layer4: resblock, input size(32,32) \n",
    "        print('Pool_3:',Pool_3.shape)\n",
    "        \n",
    "        Conv_7 = slim.conv2d(Pool_3,8*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(7))\n",
    "        ReLu_7= tf.nn.relu(Conv_7)\n",
    "        Conv_8 = slim.conv2d(ReLu_7,8*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(8))\n",
    "        ReLu_8 = tf.nn.relu(Conv_8)\n",
    "        Conv_9 = slim.conv2d(ReLu_8,8*nbFilter,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(9))\n",
    "        ReLu_9 = tf.nn.relu(Conv_9)\n",
    "        \n",
    "        # layer4: resblock, input size(32,32) \n",
    "#         print('Pool_4:',Pool_4.shape)\n",
    "        \n",
    "#         Conv_10_AC = slim.conv2d(ReLu_9,8*nbFilter,[1,1],normalizer_fn=slim.batch_norm,scope='conv_'+str(10))\n",
    "#         Tan_1 = tf.nn.relu(Conv_10_AC)\n",
    "        \n",
    "        Conv_11_AC = tf.nn.atrous_conv2d(ReLu_9,atrous_fil,rate =2,padding = 'SAME',name = 'conv_'+str(11))\n",
    "        BN_2 = slim.batch_norm(Conv_11_AC,activation_fn=None)\n",
    "        Tan_2 = tf.nn.relu(BN_2)\n",
    "        Conv_12_AC = tf.nn.atrous_conv2d(Tan_2,atrous_fil_1,rate =2,padding = 'SAME',name = 'conv_'+str(12))\n",
    "        BN_3 = slim.batch_norm(Conv_12_AC,activation_fn=None)\n",
    "        Tan_3 = tf.nn.relu(BN_3)\n",
    "        Conv_13_AC = tf.nn.atrous_conv2d(Tan_3,atrous_fil_2,rate =2,padding = 'SAME',name = 'conv_'+str(13))\n",
    "        BN_4 = slim.batch_norm(Conv_13_AC,activation_fn=None)\n",
    "        Tan_4 = tf.nn.relu(BN_4)\n",
    "        output = ReLu_9 + Tan_4\n",
    "#         output = slim.max_pool2d(output, [2, 2], scope='pool_'+str(4))\n",
    "        \n",
    "#         layer55 = tf.nn.relu(output)\n",
    "       \n",
    "        layer6 = slim.conv2d(output,8*nbFilter,[1,1],normalizer_fn=slim.batch_norm,scope='conv_'+str(14))\n",
    "        layer6 = tf.nn.relu(layer6)\n",
    "       \n",
    "                                      \n",
    "        layer7 = tf.nn.atrous_conv2d(output,atrous_fil1,rate = 3,padding = 'SAME',name='conv_'+str(15))\n",
    "        layer7 = tf.nn.relu(layer7)\n",
    "        \n",
    "                                      \n",
    "        layer8 = tf.nn.atrous_conv2d(output,atrous_fil2,rate = 5,padding = 'SAME',name='conv_'+str(16))\n",
    "        layer8 = tf.nn.relu(layer8)\n",
    "        \n",
    "                                      \n",
    "        layer9 = tf.nn.atrous_conv2d(output,atrous_fil3,rate = 7,padding = 'SAME',name='conv_'+str(17))\n",
    "        layer9 = tf.nn.relu(layer9)\n",
    "       \n",
    "        \n",
    "        layer10 = layer6+layer7+layer8+layer9\n",
    "        print('layer10:',layer10.shape)\n",
    "        \n",
    "        layer12 = tf.nn.relu(layer10)\n",
    "        layer13 = slim.max_pool2d(layer12, [2, 2], scope='pool_'+str(4))\n",
    "        print('layer13:',layer13.shape)\n",
    "     \n",
    "        # lstm network \n",
    "        \n",
    "         # lstm network \n",
    "        patches=tf.transpose(freqFeat,[1,0,2])\n",
    "        patches=tf.gather(patches,hilbert_ind)\n",
    "        patches=tf.transpose(patches,[1,0,2])         \n",
    "        # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "        xCell=tf.unstack(patches, n_steps, 1)\n",
    "        # 2 stacked layers\n",
    "        stacked_lstm_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(rnn.BasicLSTMCell(n_hidden),output_keep_prob=0.9) for _ in range(2)] )\n",
    "        out, state = rnn.static_rnn(stacked_lstm_cell, xCell, dtype=tf.float32)\n",
    "        # organizing the lstm output\n",
    "        out=tf.gather(out,actual_ind)\n",
    "        # convert to lstm output (64,batchSize,nbFilter)\n",
    "        lstm_out=tf.matmul(out,weights['out'])+biases['out']\n",
    "        lstm_out=tf.transpose(lstm_out,[1,0,2])\n",
    "        # convert to size(batchSize, 8,8, nbFilter)\n",
    "        lstm_out=tf.reshape(lstm_out,[bSize,8,8,nbFilter])\n",
    "        # perform batch normalization and activiation\n",
    "        lstm_out=slim.batch_norm(lstm_out,activation_fn=None)\n",
    "        lstm_out=tf.nn.relu(lstm_out)\n",
    "        # upsample lstm output to (batchSize, 16,16, nbFilter)\n",
    "        temp=tf.random_normal([bSize,outSize,outSize,nbFilter])\n",
    "        uShape1=tf.shape(temp)\n",
    "        upsample_filter_np = bilinear_upsample_weights(2, nbFilter)\n",
    "        upsample_filter_tensor = tf.constant(upsample_filter_np)\n",
    "        lstm_out = tf.nn.conv2d_transpose(lstm_out, upsample_filter_tensor,output_shape=uShape1,strides=[1, 2, 2, 1])\n",
    "        print('lstm_out:',lstm_out.shape)\n",
    "        # reduce the filter size to nbFilter for layer4\n",
    "        top = slim.conv2d(layer13,nbFilter,[1,1], normalizer_fn=slim.batch_norm, activation_fn=None, scope='conv_top')\n",
    "        top = tf.nn.relu(top)\n",
    "        print('top:',top.shape)\n",
    "        # concatenate both lstm features and image features\n",
    "        joint_out=tf.concat([top,lstm_out],3)\n",
    "        # perform upsampling (batchSize, 64,64, 2*nbFilter)\n",
    "        temp=tf.random_normal([bSize,outSize*4,outSize*4,2*nbFilter])\n",
    "        uShape1=tf.shape(temp)\n",
    "        upsample_filter_np = bilinear_upsample_weights(4, 2*nbFilter)\n",
    "        upsample_filter_tensor = tf.constant(upsample_filter_np)\n",
    "        upsampled_layer4 = tf.nn.conv2d_transpose(joint_out, upsample_filter_tensor,output_shape=uShape1,strides=[1, 4, 4, 1]) \t\n",
    "        # reduce filter sizes\t\n",
    "        upsampled_layer4 = slim.conv2d(upsampled_layer4,2,[1,1], normalizer_fn=slim.batch_norm, activation_fn=None, scope='conv_'+str(12))\n",
    "        upsampled_layer4=slim.batch_norm(upsampled_layer4,activation_fn=None)\n",
    "        upsampled_layer4=tf.nn.relu(upsampled_layer4)\n",
    "        # upsampling to (batchSize, 256,256, nbClasses)\n",
    "        temp=tf.random_normal([bSize,outSize*16,outSize*16,2])\n",
    "        uShape1=tf.shape(temp)\n",
    "        upsample_filter_np = bilinear_upsample_weights(4,2)\n",
    "        upsample_filter_tensor = tf.constant(upsample_filter_np)\n",
    "        upsampled_layer5 = tf.nn.conv2d_transpose(upsampled_layer4, upsample_filter_tensor,output_shape=uShape1,strides=[1, 4, 4, 1]) \n",
    "        #upsampled_layer5=slim.batch_norm(upsampled_layer5,activation_fn=None)\n",
    "        #upsampled_layer5 = slim.conv2d(upsampled_layer5,2,[3,3], normalizer_fn=slim.batch_norm, activation_fn=None, scope='conv_'+str(5))\n",
    "        #upsampled_layer5=tf.nn.relu(upsampled_layer5)\n",
    "\n",
    "\n",
    "        return upsampled_layer5\n",
    "\n",
    "\n",
    "    y1=tf.transpose(y,[1,2,3,0])\n",
    "    upsampled_logits=segNet(input_layer,batch_size,freqFeat,weights,biases)\n",
    "\n",
    "\n",
    "    flat_pred=tf.reshape(upsampled_logits,(-1,n_classes))\n",
    "    flat_y=tf.reshape(y1,(-1,n_classes))\n",
    "\n",
    "    #loss1=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=flat_pred,labels=flat_y))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(flat_y,flat_pred, 1.0))\n",
    "\n",
    "    #all_weights  = tf.trainable_variables()\n",
    "    #regLoss = tf.add_n([ tf.nn.l2_loss(v) for v in all_weights ]) * beta\n",
    "    #loss = 0.75*loss1+loss2\n",
    "    trainer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    update = trainer.minimize(loss)\n",
    "    #update2 = trainer.minimize(loss2)\n",
    "\n",
    "    probabilities=tf.nn.softmax(flat_pred)\n",
    "    correct_pred=tf.equal(tf.argmax(probabilities,1),tf.argmax(flat_y,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "    y_actual=tf.argmax(flat_y,1)\n",
    "    y_pred=tf.argmax(flat_pred,1)\n",
    "\n",
    "    mask_actual= tf.argmax(y1,3)\n",
    "    mask_pred=tf.argmax(upsampled_logits,3)\n",
    "\n",
    "\n",
    "# Initializing the variables\n",
    "# init = tf.initialize_all_variables()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config=tf.ConfigProto()\n",
    "config.allow_soft_placement=True\n",
    "config.log_device_placement=True\n",
    "config.gpu_options.allow_growth=True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T05:06:56.454775Z",
     "start_time": "2019-06-19T04:50:47.105526Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading Synthesized data\n",
    "# freq1 = np.load('../dataset_npy/synthesized_imgs/Synthesized_imgS_feat.npy')\n",
    "\n",
    "Img = np.load('../dataset_npy/synthesized_imgs/Synthesized_imgS.npy')\n",
    "print('Img.....OK')\n",
    "Lab = np.load('../dataset_npy/synthesized_imgs/Synthesized_labelS.npy')\n",
    "print('Lab....OK')\n",
    "freq1 = np.load('../dataset_npy/synthesized_imgs/Synthesized_imgS_cohere_feat.npy')\n",
    "print('freq1...OK')\n",
    "\n",
    "\n",
    "# loading NC_16 data for pretrain\n",
    "Img_NC16 = np.load('../dataset_npy/NC_16/train/NC16_train_img.npy')\n",
    "Img_NC16_img=np.shape(Img_NC16)\n",
    "print ('Img_NC16_img.shape=',Img_NC16_img)\n",
    "Lab_NC16 = np.load('../dataset_npy/NC_16/train/NC16_train_label.npy')\n",
    "# feat_nc16 = np.load('../dataset_npy/NC_16/train/NC16_train_img_feat.npy')\n",
    "feat_nc16 = np.load('../dataset_npy/NC_16/train/NC16_train_img_cohere_feat.npy')\n",
    "\n",
    "vx=Img_NC16[-40:]\n",
    "vx1=feat_nc16[-40:]\n",
    "vy=Lab_NC16[-40:]\n",
    "\n",
    "\n",
    "Img_NC16 = Img_NC16[:-40]\n",
    "Lab_NC16 = Lab_NC16[:-40]\n",
    "feat_nc16 = feat_nc16[:-40]\n",
    "print('Img_NC16.shape=',Img_NC16.shape)\n",
    "\n",
    "tx = np.load('../dataset_npy/NC_16/test/NC16_test_img.npy')\n",
    "ty = np.load('../dataset_npy/NC_16/test/NC16_test_label.npy')\n",
    "# freq4 = np.load('../dataset_npy/NC_16/test/NC16_test_img_feat.npy')\n",
    "freq4 = np.load('../dataset_npy/NC_16/test/NC16_test_img_cohere_feat.npy')\n",
    "print('freq4.shape=',freq4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T02:27:42.841765Z",
     "start_time": "2019-07-27T02:27:42.835306Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def next_batch(size, batch_size, batch_ratio=1.0):\n",
    "    import random\n",
    "    rand = list(range(size))\n",
    "    while True:\n",
    "        random.shuffle(rand)\n",
    "        for i in range(int(batch_ratio * size // batch_size)):\n",
    "            yield rand[i*batch_size:(i+1)*batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T02:27:45.366737Z",
     "start_time": "2019-07-27T02:27:45.353800Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_pos_neg(y_actual, y_hat):\n",
    "    TP = 0; FP = 0;TN = 0; FN = 0\n",
    "#     print('y_hat_shape',y_hat.shape)\n",
    "#     print('y_actual_shape',y_actual.shape)\n",
    "#     print('y_hat',y_hat)\n",
    "#     print('y_actual',y_actual)\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "            TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "            FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "            TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "            FN += 1\n",
    "\n",
    "    return TP,FP,TN,FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T02:27:48.982260Z",
     "start_time": "2019-07-27T02:27:48.968498Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def metrics(TP,FP,TN,FN):\n",
    "    a=TP+FP\n",
    "    b=TP+FN\n",
    "    c=TN+FP\n",
    "    d=TN+FN\n",
    "    mcc=((TP*TN)-(FP*FN))/(math.sqrt(float(a*b*c*d)+0.0001))\n",
    "    F1=(2*TP)/float(2*TP+FP+FN+.0000001)\n",
    "    precision=TP/float(TP+FP+.0000001)\n",
    "    #recall=TP/float(TP+FN+.0000001)\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T22:55:02.572293Z",
     "start_time": "2019-05-17T14:08:35.536893Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_freq =1\n",
    "learn_step =0\n",
    "learn_rate = 0.00003\n",
    "train_step = 100000\n",
    "batch_size = 32\n",
    "with tf.Session(config=config) as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    tnb = next_batch(Lab.shape[0], batch_size)\n",
    "    vnb = next_batch(vx.shape[0], batch_size)\n",
    "    total_epoch = math.ceil(train_step / (Lab.shape[0] // batch_size))\n",
    "    print('total_epoch=',total_epoch)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        train_loss = 0\n",
    "        train_batches = int(show_freq * Lab.shape[0] // batch_size)\n",
    "        print('train_batches=',train_batches)\n",
    "        \n",
    "        for i in range(train_batches):\n",
    "#             print('\\ri: %d'%i)\n",
    "            sys.stdout.write('\\r' + str(i))\n",
    "            sys.stdout.flush()\n",
    "#             print('\\ri: %d'%i,  end= flush=True)\n",
    "            select = next(tnb)\n",
    "            \n",
    "            batch_x = Img[select]\n",
    "            batch_y = Lab[select]\n",
    "            batch_x1 = freq1[select]\n",
    "            \n",
    "            rev_batch_y=np.array(conv_mask_gt(batch_y))\n",
    "            batch_x=np.multiply(batch_x,1.0/mx)\n",
    "            sess.run(update, feed_dict={input_layer: batch_x, y: rev_batch_y, freqFeat: batch_x1})\n",
    "            train_loss += sess.run(loss, feed_dict={input_layer: batch_x, y: rev_batch_y, freqFeat: batch_x1})\n",
    "            \n",
    "            learn_step +=1  \n",
    "        train_loss /= train_batches\n",
    "        vali_loss = 0\n",
    "        vali_accuracy = 0\n",
    "        vali_batches = vx.shape[0]//batch_size\n",
    "        print()\n",
    "        \n",
    "        print('vali_batches=',vali_batches)\n",
    "        for j in range(vali_batches):\n",
    "#             print('\\rj: %d'%j)\n",
    "            select = next(vnb)\n",
    "            batch_X = vx[select]\n",
    "            batch_Y  = vy[select]\n",
    "            batch_X1 = vx1[select]\n",
    "            batch_X=np.multiply(batch_X,1.0/mx)\n",
    "            rev_batch_y=np.array(conv_mask_gt(batch_Y))\n",
    "\n",
    "            vali_loss += sess.run(loss, feed_dict={input_layer: batch_X, y: rev_batch_y, freqFeat: batch_X1})\n",
    "            vali_accuracy += sess.run(accuracy, feed_dict={input_layer: batch_X, y: rev_batch_y, freqFeat: batch_X1})\n",
    "        vali_loss /= vali_batches\n",
    "        vali_accuracy /= vali_batches\n",
    "        \n",
    "        epoch = math.ceil(learn_step / (Lab.shape[0] // batch_size)) \n",
    "        print()\n",
    "        print(datetime.datetime.now( ).strftime('%m-%d %H:%M:%S') + \n",
    "                  ' | Step:%6d(%3d/%3d) LR:%.6f TLoss:%.6f VLoss:%f VAcc:%f' % (\n",
    "                      learn_step, epoch, total_epoch, learn_rate, train_loss, vali_loss, vali_accuracy))\n",
    "        if learn_step > train_step:\n",
    "                break\n",
    "        print('learn_step=',learn_step)\n",
    "        if learn_step % int(show_freq * train_batches)==0:\n",
    "            \n",
    "            \n",
    "            TP = 0; FP = 0;TN = 0; FN = 0 \n",
    "            #TP1=0;FP1=0\n",
    "            num_images=batch_size\n",
    "            n_chunks=np.shape(tx)[0]//batch_size\n",
    "            tAcc=np.zeros(n_chunks)\n",
    "\n",
    "            for chunk in range(0,n_chunks):               \n",
    "                tx_batch=tx[((chunk)*num_images):((chunk+1)*num_images),...]\n",
    "                ty_batch=ty[((chunk)*num_images):((chunk+1)*num_images),...]\n",
    "                tx1_batch=freq4[((chunk)*num_images):((chunk+1)*num_images),...]\n",
    "                ty_batch=conv_mask_gt(ty_batch)\n",
    "                tAcc[chunk],y2,p2=sess.run([accuracy,y_actual,y_pred], feed_dict={input_layer: tx_batch, y:ty_batch, freqFeat: tx1_batch})\n",
    "                a,b,c,d=compute_pos_neg(y2,p2)\n",
    "\n",
    "                TP+=a; FP+=b;TN+=c; FN+=d\n",
    "                \n",
    "            print(\"TP =\",TP)\n",
    "            print(\"FP = \",FP)\n",
    "            print(\"TN = \",TN)\n",
    "            print(\"FN = \",FN)\n",
    "            \n",
    "            prec=metrics(TP,FP,TN,FN)            \n",
    "            test_accuracy=np.mean(tAcc)\n",
    "            print(\"prec = \",prec)\n",
    "            print(\"test_accuracy = \",test_accuracy)\n",
    "           \n",
    "            if prec > 0.45 :\n",
    "                best_prec = prec\n",
    "                save_path=saver.save(sess,'../model_shi/final_model_nist.ckpt')\n",
    "                print (\"Best Model Found on NC16...\")\n",
    "                print ( \"prec = \"+str(prec) + \", acc = \"+ str(test_accuracy))\n",
    "\n",
    "            saver.save(sess, '../model_shi/modelS%d.ckpt' % learn_step)\n",
    "            \n",
    "        \n",
    "    saver.save(sess, '../model_shi/modelS.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T02:32:07.513816Z",
     "start_time": "2019-05-22T11:16:56.302635Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_freq =1\n",
    "learn_step =0\n",
    "learn_rate = 0.00003\n",
    "train_step = 100000\n",
    "batch_size = 30\n",
    "with tf.Session(config=config) as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    tnb = next_batch(Lab.shape[0], batch_size)\n",
    "    vnb = next_batch(vx.shape[0], batch_size)\n",
    "    total_epoch = math.ceil(train_step / (Lab.shape[0] // batch_size))\n",
    "    print('total_epoch=',total_epoch)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        train_loss = 0\n",
    "        train_batches = int(show_freq * Lab.shape[0] // batch_size)\n",
    "        print('train_batches=',train_batches)\n",
    "        \n",
    "        for i in range(train_batches):\n",
    "#             print('\\ri: %d'%i)\n",
    "            sys.stdout.write('\\r' + str(i))\n",
    "            sys.stdout.flush()\n",
    "#             print('\\ri: %d'%i,  end= flush=True)\n",
    "            select = next(tnb)\n",
    "            \n",
    "            batch_x = Img[select]\n",
    "            batch_y = Lab[select]\n",
    "            batch_x1 = freq1[select]\n",
    "            \n",
    "            rev_batch_y=np.array(conv_mask_gt(batch_y))\n",
    "            batch_x=np.multiply(batch_x,1.0/mx)\n",
    "            sess.run(update, feed_dict={input_layer: batch_x, y: rev_batch_y, freqFeat: batch_x1})\n",
    "            train_loss += sess.run(loss, feed_dict={input_layer: batch_x, y: rev_batch_y, freqFeat: batch_x1})\n",
    "            \n",
    "            learn_step +=1  \n",
    "        train_loss /= train_batches\n",
    "        vali_loss = 0\n",
    "        vali_accuracy = 0\n",
    "        vali_batches = vx.shape[0]//batch_size\n",
    "        print()\n",
    "        \n",
    "        print('vali_batches=',vali_batches)\n",
    "        for j in range(vali_batches):\n",
    "#             print('\\rj: %d'%j)\n",
    "            select = next(vnb)\n",
    "            batch_X = vx[select]\n",
    "            batch_Y  = vy[select]\n",
    "            batch_X1 = vx1[select]\n",
    "            batch_X=np.multiply(batch_X,1.0/mx)\n",
    "            rev_batch_y=np.array(conv_mask_gt(batch_Y))\n",
    "\n",
    "            vali_loss += sess.run(loss, feed_dict={input_layer: batch_X, y: rev_batch_y, freqFeat: batch_X1})\n",
    "            vali_accuracy += sess.run(accuracy, feed_dict={input_layer: batch_X, y: rev_batch_y, freqFeat: batch_X1})\n",
    "        vali_loss /= vali_batches\n",
    "        vali_accuracy /= vali_batches\n",
    "        \n",
    "        epoch = math.ceil(learn_step / (Lab.shape[0] // batch_size)) \n",
    "        print()\n",
    "        print(datetime.datetime.now( ).strftime('%m-%d %H:%M:%S') + \n",
    "                  ' | Step:%6d(%3d/%3d) LR:%.6f TLoss:%.6f VLoss:%f VAcc:%f' % (\n",
    "                      learn_step, epoch, total_epoch, learn_rate, train_loss, vali_loss, vali_accuracy))\n",
    "        if learn_step > train_step:\n",
    "                break\n",
    "        print('learn_step=',learn_step)\n",
    "        if learn_step % int(show_freq * train_batches)==0:\n",
    "            \n",
    "            \n",
    "            TP = 0; FP = 0;TN = 0; FN = 0 \n",
    "            #TP1=0;FP1=0\n",
    "            num_images=batch_size\n",
    "            n_chunks=np.shape(tx)[0]//batch_size\n",
    "            tAcc=np.zeros(n_chunks)\n",
    "\n",
    "            for chunk in range(0,n_chunks):               \n",
    "                tx_batch=tx[((chunk)*num_images):((chunk+1)*num_images),...]\n",
    "                ty_batch=ty[((chunk)*num_images):((chunk+1)*num_images),...]\n",
    "                tx1_batch=freq4[((chunk)*num_images):((chunk+1)*num_images),...]\n",
    "                ty_batch=conv_mask_gt(ty_batch)\n",
    "                tAcc[chunk],y2,p2=sess.run([accuracy,y_actual,y_pred], feed_dict={input_layer: tx_batch, y:ty_batch, freqFeat: tx1_batch})\n",
    "                a,b,c,d=compute_pos_neg(y2,p2)\n",
    "\n",
    "                TP+=a; FP+=b;TN+=c; FN+=d\n",
    "            \n",
    "            prec=metrics(TP,FP,TN,FN)            \n",
    "            test_accuracy=np.mean(tAcc)\n",
    "       \n",
    "            print(' | TP%d FP:%d TN:%d FN:%d----prec:%.6f-----Tacc:%.6f' % (TP, FP, TN, FN, prec, test_accuracy))\n",
    "            \n",
    "            if prec > 0.30 :\n",
    "                best_prec = prec\n",
    "                save_path=saver.save(sess,'../model_s_gaijin1/final_model_nist.ckpt')\n",
    "                print (\"Best Model Found on NC16...\")\n",
    "                print ( \"prec = \"+str(prec) + \", acc = \"+ str(test_accuracy))\n",
    "\n",
    "            saver.save(sess, '../model_s_gaijin1/modelS%d.ckpt' % learn_step)\n",
    "            \n",
    "        \n",
    "    saver.save(sess, '../model_s_gaijin1/modelS.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T22:01:28.406638Z",
     "start_time": "2019-06-10T06:55:33.366584Z"
    }
   },
   "outputs": [],
   "source": [
    "show_freq =1\n",
    "learn_step =0\n",
    "learn_rate = 0.00003\n",
    "train_step = 100000\n",
    "batch_size = 30\n",
    "with tf.Session(config=config) as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    tnb = next_batch(Lab.shape[0], batch_size)\n",
    "    vnb = next_batch(vx.shape[0], batch_size)\n",
    "    total_epoch = math.ceil(train_step / (Lab.shape[0] // batch_size))\n",
    "    print('total_epoch=',total_epoch)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        train_loss = 0\n",
    "        train_batches = int(show_freq * Lab.shape[0] // batch_size)\n",
    "#         print('train_batches=',train_batches)\n",
    "        \n",
    "        for i in range(train_batches):\n",
    "            sys.stdout.write('\\r' + str(i))\n",
    "            sys.stdout.flush()\n",
    "            select = next(tnb)\n",
    "            \n",
    "            batch_x = Img[select]\n",
    "            batch_y = Lab[select]\n",
    "            batch_x1 = freq1[select]\n",
    "\n",
    "            rev_batch_y=np.array(conv_mask_gt(batch_y))\n",
    "            batch_x=np.multiply(batch_x,1.0/mx)\n",
    "            sess.run(update, feed_dict={input_layer: batch_x, y: rev_batch_y, freqFeat: batch_x1})\n",
    "            train_loss += sess.run(loss, feed_dict={input_layer: batch_x, y: rev_batch_y, freqFeat: batch_x1})\n",
    "            \n",
    "            learn_step +=1  \n",
    "        train_loss /= train_batches\n",
    "        vali_loss = 0\n",
    "        vali_accuracy = 0\n",
    "        vali_batches = vx.shape[0]//batch_size\n",
    "#         print()\n",
    "        \n",
    "#         print('vali_batches=',vali_batches)\n",
    "        for j in range(vali_batches):\n",
    "#             print('\\rj: %d'%j)\n",
    "            select = next(vnb)\n",
    "            batch_X = vx[select]\n",
    "            batch_Y  = vy[select]\n",
    "            batch_X1 = vx1[select]\n",
    "            batch_X=np.multiply(batch_X,1.0/mx)\n",
    "            rev_batch_y=np.array(conv_mask_gt(batch_Y))\n",
    "\n",
    "            vali_loss += sess.run(loss, feed_dict={input_layer: batch_X, y: rev_batch_y, freqFeat: batch_X1})\n",
    "            vali_accuracy += sess.run(accuracy, feed_dict={input_layer: batch_X, y: rev_batch_y, freqFeat: batch_X1})\n",
    "        vali_loss /= vali_batches\n",
    "        vali_accuracy /= vali_batches\n",
    "        \n",
    "        epoch = math.ceil(learn_step / (Lab.shape[0] // batch_size)) \n",
    "       \n",
    "        print(datetime.datetime.now( ).strftime('%m-%d %H:%M:%S') + \n",
    "                  ' | Step:%6d(%3d/%3d) LR:%.6f TLoss:%.6f VLoss:%f VAcc:%f' % (\n",
    "                      learn_step, epoch, total_epoch, learn_rate, train_loss, vali_loss, vali_accuracy))\n",
    "        if learn_step > train_step:\n",
    "                break\n",
    "        print('learn_step=',learn_step)\n",
    "        if learn_step % int(show_freq * train_batches)==0:\n",
    "            \n",
    "            \n",
    "            TP = 0; FP = 0;TN = 0; FN = 0 \n",
    "            #TP1=0;FP1=0\n",
    "            num_images=batch_size\n",
    "            n_chunks=np.shape(tx)[0]//batch_size\n",
    "            tAcc=np.zeros(n_chunks)\n",
    "\n",
    "            for chunk in range(0,n_chunks):               \n",
    "                tx_batch=tx[((chunk)*num_images):((chunk+1)*num_images),...]\n",
    "                ty_batch=ty[((chunk)*num_images):((chunk+1)*num_images),...]\n",
    "                tx1_batch=freq4[((chunk)*num_images):((chunk+1)*num_images),...]\n",
    "                ty_batch=conv_mask_gt(ty_batch)\n",
    "                tAcc[chunk],y2,p2=sess.run([accuracy,y_actual,y_pred], feed_dict={input_layer: tx_batch, y:ty_batch, freqFeat: tx1_batch})\n",
    "                a,b,c,d=compute_pos_neg(y2,p2)\n",
    "\n",
    "                TP+=a; FP+=b;TN+=c; FN+=d\n",
    "            \n",
    "            prec=metrics(TP,FP,TN,FN)            \n",
    "            test_accuracy=np.mean(tAcc)\n",
    "       \n",
    "            print(' | TP%d FP:%d TN:%d FN:%d----prec:%.6f-----Tacc:%.6f' % (TP, FP, TN, FN, prec, test_accuracy))\n",
    "            \n",
    "            if prec > 0.45 :\n",
    "                best_prec = prec\n",
    "                save_path=saver.save(sess,'../model_s/final_model_nist.ckpt')\n",
    "                print (\"Best Model Found on NC16...\")\n",
    "                print ( \"prec = \"+str(prec) + \", acc = \"+ str(test_accuracy))\n",
    "\n",
    "            saver.save(sess, '../model_s/modelS%d.ckpt' % learn_step)\n",
    "            \n",
    "        \n",
    "    saver.save(sess, '../model_s/modelS.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-25T07:21:49.736Z"
    }
   },
   "outputs": [],
   "source": [
    "show_freq =1\n",
    "learn_step =0\n",
    "learn_rate = 0.00003\n",
    "train_step = 1000000\n",
    "batch_size = 30\n",
    "with tf.Session(config=config) as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    tnb = next_batch(Lab.shape[0], batch_size)\n",
    "#     vnb = next_batch(vx.shape[0], batch_size)\n",
    "    total_epoch = math.ceil(train_step / (Lab.shape[0] // batch_size))\n",
    "    print('total_epoch=',total_epoch)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        train_loss = 0\n",
    "        train_accuracy = 0\n",
    "        train_batches = int(show_freq * Lab.shape[0] // batch_size)\n",
    "#         print('train_batches=',train_batches)\n",
    "        \n",
    "        for i in range(train_batches):\n",
    "#             print('\\ri: %d'%i)\n",
    "            sys.stdout.write('\\r' + str(i))\n",
    "            sys.stdout.flush()\n",
    "#             print('\\ri: %d'%i,  end= flush=True)\n",
    "            select = next(tnb)\n",
    "            \n",
    "            batch_x = Img[select]\n",
    "            batch_y = Lab[select]\n",
    "            batch_x1 = freq1[select]\n",
    "            \n",
    "            rev_batch_y=np.array(conv_mask_gt(batch_y))\n",
    "            batch_x=np.multiply(batch_x,1.0/mx)\n",
    "            sess.run(update, feed_dict={input_layer: batch_x, y: rev_batch_y})\n",
    "            train_loss += sess.run(loss, feed_dict={input_layer: batch_x, y: rev_batch_y})\n",
    "            train_accuracy += sess.run(accuracy, feed_dict={input_layer: batch_x, y: rev_batch_y})\n",
    "            learn_step +=1  \n",
    "        train_loss /= train_batches\n",
    "        \n",
    "        train_accuracy /= train_batches\n",
    "#         vali_loss = 0\n",
    "#         vali_accuracy = 0\n",
    "#         vali_batches = vx.shape[0]//batch_size\n",
    "        \n",
    "        \n",
    "#         print('vali_batches=',vali_batches)\n",
    "#         for j in range(vali_batches):\n",
    "# #             print('\\rj: %d'%j)\n",
    "#             select = next(vnb)\n",
    "#             batch_X = vx[select]\n",
    "#             batch_Y  = vy[select]\n",
    "#             batch_X1 = vx1[select]\n",
    "#             batch_X=np.multiply(batch_X,1.0/mx)\n",
    "#             rev_batch_y=np.array(conv_mask_gt(batch_Y))\n",
    "\n",
    "#             vali_loss += sess.run(loss, feed_dict={input_layer: batch_X, y: rev_batch_y, freqFeat: batch_X1})\n",
    "#             vali_accuracy += sess.run(accuracy, feed_dict={input_layer: batch_X, y: rev_batch_y, freqFeat: batch_X1})\n",
    "#         vali_loss /= vali_batches\n",
    "#         vali_accuracy /= vali_batches\n",
    "        \n",
    "        epoch = math.ceil(learn_step / (Lab.shape[0] // batch_size)) \n",
    "        print()\n",
    "        \n",
    "        if learn_step > train_step:\n",
    "                break\n",
    "        print('learn_step=',learn_step)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if learn_step % int(show_freq * train_batches)==0:\n",
    "            \n",
    "            \n",
    "            TP = 0; FP = 0;TN = 0; FN = 0 \n",
    "            #TP1=0;FP1=0\n",
    "            num_images=batch_size\n",
    "            n_chunks=np.shape(tx)[0]//batch_size\n",
    "            tAcc=np.zeros(n_chunks)\n",
    "            vali_loss = 0\n",
    "            for chunk in range(0,n_chunks):               \n",
    "                tx_batch=tx[((chunk)*num_images):((chunk+1)*num_images),...]\n",
    "                tx_batch=np.multiply(tx_batch,1.0/mx)\n",
    "                ty_batch=ty[((chunk)*num_images):((chunk+1)*num_images),...]\n",
    "                tx1_batch=freq4[((chunk)*num_images):((chunk+1)*num_images),...]\n",
    "                ty_batch=conv_mask_gt(ty_batch)\n",
    "                \n",
    "                vali_loss += sess.run(loss, feed_dict={input_layer: tx_batch, y:ty_batch})\n",
    "        \n",
    "                \n",
    "                tAcc[chunk],y2,p2=sess.run([accuracy,y_actual,y_pred], feed_dict={input_layer: tx_batch, y:ty_batch})\n",
    "                a,b,c,d=compute_pos_neg(y2,p2)\n",
    "\n",
    "                TP+=a; FP+=b;TN+=c; FN+=d\n",
    "            vali_loss /= n_chunks\n",
    "            prec=metrics(TP,FP,TN,FN)            \n",
    "            test_accuracy=np.mean(tAcc)\n",
    "            print(datetime.datetime.now( ).strftime('%m-%d %H:%M:%S') + \n",
    "                  ' | Step:%6d(%3d/%3d) LR:%.6f TrainLoss:%.6f ValiLoss:%f TrainAcc:%.6f' % (\n",
    "                      learn_step, epoch, total_epoch, learn_rate, train_loss, vali_loss,train_accuracy))\n",
    "\n",
    "            print(' | TP%d FP:%d TN:%d FN:%d----prec:%.6f-----Tacc:%.6f' % (TP, FP, TN, FN, prec, test_accuracy))\n",
    "            \n",
    "            if prec > 0.55 :\n",
    "                best_prec = prec\n",
    "                save_path=saver.save(sess,'../model_s/final_model_nist.ckpt')\n",
    "                print (\"Best Model Found on NC16...\")\n",
    "                print ( \"prec = \"+str(prec) + \", acc = \"+ str(test_accuracy))\n",
    "\n",
    "            saver.save(sess, '../model_s/modelS%d.ckpt' % learn_step)\n",
    "            \n",
    "        \n",
    "    saver.save(sess, '../model_s/modelS.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "477.455px",
    "left": "46px",
    "top": "130.364px",
    "width": "212px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
